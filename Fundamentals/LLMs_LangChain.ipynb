{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629f59a7",
   "metadata": {},
   "source": [
    "# LLM Fundamentals with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2db46b",
   "metadata": {},
   "source": [
    "## Using LLMs in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167db0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...blue! (or maybe grey, or cloudy, or sunny...) What were you going to say?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLMs\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model='llama3.1')\n",
    "\n",
    "model.invoke(\"The sky is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654bf3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-24T14:31:15.3324601Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1180698400, 'load_duration': 109208800, 'prompt_eval_count': 17, 'prompt_eval_duration': 413545100, 'eval_count': 8, 'eval_duration': 650112000, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--85082919-006a-4d56-a4c4-baf469dcd87f-0', usage_metadata={'input_tokens': 17, 'output_tokens': 8, 'total_tokens': 25})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Model\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5430463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-24T14:31:16.8282216Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1469849700, 'load_duration': 93859400, 'prompt_eval_count': 37, 'prompt_eval_duration': 1172635500, 'eval_count': 3, 'eval_duration': 183269000, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--3eb70514-d595-405b-bc97-e1c83da684fe-0', usage_metadata={'input_tokens': 37, 'output_tokens': 3, 'total_tokens': 40})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Model with SystemMessage interaction\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "system_msg = SystemMessage(\n",
    "    '''You are a helpful assistant that responds to questions with three exclamation marks.'''\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    '''What is the capital of France?'''\n",
    ")\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda37149",
   "metadata": {},
   "source": [
    "## Making LLM Prompts Reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495ee68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OpenAI and Cohere offer LLMs through their respective libraries ('openai' and 'cohere').\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# both 'template' and 'model' can be reused many times\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    '''Answer the question based on the context below. \n",
    "    If the question cannot be answered using the information provided, answer \"I don't know.\"\n",
    "\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "\n",
    "    Answer:'''\n",
    ")\n",
    "\n",
    "model = OllamaLLM(model='llama3.1')\n",
    "\n",
    "# 'prompt' and 'completion' are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperforms their\n",
    "        smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers\n",
    "        can tap into tese models through Hugging Face's 'transformers' library, or by utilizing OpenAI and Cohere's offerings through the\n",
    "        'openai' and 'cohere' libraries, respectively.\"\"\",\n",
    "    \"question\":\"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316d54c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hugging Face ('transformers' library), OpenAI ('openai' library), and Cohere ('cohere' library) offer Large Language Models (LLMs).\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-24T14:41:04.4695804Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15346473400, 'load_duration': 6982090000, 'prompt_eval_count': 148, 'prompt_eval_duration': 5250743800, 'eval_count': 35, 'eval_duration': 3084087000, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--b4019ef5-6dd2-4b55-8640-634b0bee301b-0', usage_metadata={'input_tokens': 148, 'output_tokens': 35, 'total_tokens': 183})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# both 'template' and 'model' can be reused many times\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Answer the question basen on the context below. If the question cannot be answered using hte information provided,\n",
    "        answer with \"I don't know\".'''),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Question: {question}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "# 'prompt' and 'completion' are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperforms their\n",
    "        smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers\n",
    "        can tap into tese models through Hugging Face's 'transformers' library, or by utilizing OpenAI and Cohere's offerings through the\n",
    "        'openai' and 'cohere' libraries, respectively.\"\"\",\n",
    "    \"question\":\"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cfcca",
   "metadata": {},
   "source": [
    "## Getting Specific Formats out of LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de890c9c",
   "metadata": {},
   "source": [
    "### JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8052a668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='They weigh the same!', justification=\"One pound is a unit of weight, so it's equal to one pound regardless of what you're measuring. The difference is in their density and volume.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    \"\"\"An answer to the user's question along with justification for the answer.\"\"\"\n",
    "    answer: str\n",
    "    \"\"\"The answer to the user's question\"\"\"\n",
    "    justification: str\n",
    "    \"\"\"Justification for the answer\"\"\"\n",
    "\n",
    "llm = ChatOllama(model='llama3.1', temperature=0)\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "structured_llm.invoke(\"What weighs more, a pound of bricks or a pound of feathers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da458783",
   "metadata": {},
   "source": [
    "### Other Machine-Readable Formats with Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f757699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"apple, banana, cherry\")\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09d007",
   "metadata": {},
   "source": [
    "## Assembling the Many Pieces of an LLM Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a79d2",
   "metadata": {},
   "source": [
    "### Using the Runnable Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63867f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"How's it going? Is there something I can help you with or would you like to chat?\" additional_kwargs={} response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:28:29.9338158Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11136677900, 'load_duration': 8536520000, 'prompt_eval_count': 13, 'prompt_eval_duration': 636706900, 'eval_count': 21, 'eval_duration': 1934901600, 'model_name': 'llama3.1', 'model_provider': 'ollama'} id='lc_run--28688c97-569b-4c7c-ac17-13eb8df58de1-0' usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34}\n",
      "[AIMessage(content=\"How's it going? Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:28:31.9972715Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2044071800, 'load_duration': 135746200, 'prompt_eval_count': 13, 'prompt_eval_duration': 99911100, 'eval_count': 21, 'eval_duration': 1795024100, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--41eacc40-5338-4a48-b1d8-f9e33281a3a0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 21, 'total_tokens': 34}), AIMessage(content='Bye! It was nice chatting with you, even if it was just a quick hello and goodbye. If you ever need anything or want to chat again, feel free to come back anytime. Have a great day!', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:28:36.2950589Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6341351600, 'load_duration': 138520600, 'prompt_eval_count': 13, 'prompt_eval_duration': 296758300, 'eval_count': 45, 'eval_duration': 3974179300, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--6e0907ff-4a7f-423b-87f7-13d3bc334914-0', usage_metadata={'input_tokens': 13, 'output_tokens': 45, 'total_tokens': 58})]\n",
      "content='It' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' was' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' nice' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' chatting' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' even' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' if' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' it' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' was' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' just' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' moment' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' If' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' need' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' anything' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' or' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' want' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' chat' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' again' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' sometime' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' feel' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' free' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' come' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' back' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content='!' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' Have' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' great' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' day' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content='!' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content=' Bye' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content='!' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:28:40.2578898Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3957372300, 'load_duration': 115166200, 'prompt_eval_count': 13, 'prompt_eval_duration': 121129800, 'eval_count': 41, 'eval_duration': 3689901100, 'model_name': 'llama3.1', 'model_provider': 'ollama'} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d' usage_metadata={'input_tokens': 13, 'output_tokens': 41, 'total_tokens': 54}\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--c546b3db-1e49-409e-bb24-a838718d775d' chunk_position='last'\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "completion = model.invoke('Hi there!')\n",
    "print(completion)\n",
    "\n",
    "completions = model.batch(['Hi there!', 'Bye!'])\n",
    "print(completions)\n",
    "\n",
    "for token in model.stream('Bye!'):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdfe134",
   "metadata": {},
   "source": [
    "### Imperative Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b31455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='There are several model providers that offer Large Language Models (LLMs). Here are some of the most popular ones:\\n\\n1. **Hugging Face**: Hugging Face offers a range of pre-trained LLMs, including BERT, RoBERTa, and Longformer, through their Transformers library.\\n2. **Google Cloud AI Platform**: Google Cloud AI Platform provides access to pre-trained LLMs like BERT, RoBERTa, and XLNet, which can be fine-tuned for specific tasks.\\n3. **Microsoft Azure Machine Learning**: Microsoft Azure Machine Learning offers a range of pre-trained LLMs, including BERT and RoBERTa, which can be used for natural language processing (NLP) tasks.\\n4. **Amazon SageMaker**: Amazon SageMaker provides access to pre-trained LLMs like BERT and RoBERTa, which can be fine-tuned for specific NLP tasks.\\n5. **DeepMind**: DeepMind offers a range of pre-trained LLMs, including Transformer-XL and XLNet, through their TensorFlow framework.\\n6. **Meta AI**: Meta AI provides access to pre-trained LLMs like BERT and RoBERTa, which can be fine-tuned for specific NLP tasks.\\n7. **IBM Watson Studio**: IBM Watson Studio offers a range of pre-trained LLMs, including BERT and RoBERTa, which can be used for NLP tasks.\\n8. **NVIDIA NGC**: NVIDIA NGC provides access to pre-trained LLMs like BERT and RoBERTa, which can be fine-tuned for specific NLP tasks.\\n\\nThese model providers offer a range of benefits, including:\\n\\n* Pre-trained models that can be fine-tuned for specific tasks\\n* Easy integration with popular frameworks like TensorFlow and PyTorch\\n* Scalability and performance optimization\\n* Regular updates and maintenance of the models\\n\\nKeep in mind that this is not an exhaustive list, and there are many other model providers offering LLMs. Additionally, some of these providers may have specific requirements or limitations for using their pre-trained models.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:38:45.6251589Z', 'done': True, 'done_reason': 'stop', 'total_duration': 48153428200, 'load_duration': 6739667200, 'prompt_eval_count': 28, 'prompt_eval_duration': 1175279500, 'eval_count': 422, 'eval_duration': 40005871200, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--f199e0c9-f2b3-4bfa-89df-3015abc7add8-0', usage_metadata={'input_tokens': 28, 'output_tokens': 422, 'total_tokens': 450})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "# use it\n",
    "\n",
    "chatbot.invoke({'question': 'Which model providers offer LLMs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3412e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Several' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' provide' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Large' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LL' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Ms' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=')' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' applications' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' research' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' development' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' production' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' use' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' cases' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Here' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' some' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' notable' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' ones' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=':\\n\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='1' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='H' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='ugging' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Face' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Transformers' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' H' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='ugging' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Face' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' offers' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' wide' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' range' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' pre' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='-trained' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' through' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' their' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Transformers' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' library' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' which' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' includes' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' popular' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' B' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='ERT' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Ro' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='BERT' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' XL' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Net' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='2' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Google' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Cloud' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Platform' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Google' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Cloud' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' provides' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' managed' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' service' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' building' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' deploying' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' managing' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' using' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' TensorFlow' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' framework' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='3' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Amazon' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Sage' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Maker' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Amazon' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=\"'s\" additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Sage' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Maker' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' fully' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' managed' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' service' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' allows' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' users' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' build' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' train' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' deploy' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' machine' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' learning' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' using' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' frameworks' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' TensorFlow' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Py' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='T' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='orch' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='4' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Microsoft' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Azure' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Machine' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Learning' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Microsoft' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=\"'s\" additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Azure' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' ML' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' provides' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' cloud' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='-based' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' platform' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' building' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' deploying' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' managing' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' using' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Azure' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Machine' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Learning' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' service' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='5' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='IBM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Watson' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Studio' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' IBM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=\"'s\" additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Watson' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Studio' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' an' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' integrated' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' development' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' environment' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='IDE' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=')' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' allows' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' users' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' build' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' train' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' deploy' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' machine' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' learning' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' using' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' frameworks' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' TensorFlow' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Py' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='T' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='orch' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='6' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Deep' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Mind' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Deep' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Mind' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' provides' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' access' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' their' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' proprietary' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' architecture' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Transformer' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='-X' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' through' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' their' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Alpha' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Fold' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' API' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='7' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Meta' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Meta' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' offers' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' range' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' pre' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='-trained' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Switch' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Transformers' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' Marian' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='MT' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' N' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LP' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' tasks' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='These' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' just' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' few' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' examples' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' model' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' providers' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' offer' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='s' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' There' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' many' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' more' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=',' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' new' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' ones' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' emerging' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' as' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' field' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' continues' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' evolve' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='Is' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' there' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' anything' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' specific' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=\"'d\" additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' know' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' about' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' these' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' or' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' their' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content=' applications' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='?' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:41:51.5969473Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33535299100, 'load_duration': 153915300, 'prompt_eval_count': 29, 'prompt_eval_duration': 294740700, 'eval_count': 347, 'eval_duration': 32861703700, 'model_name': 'llama3.1', 'model_provider': 'ollama'} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba' usage_metadata={'input_tokens': 29, 'output_tokens': 347, 'total_tokens': 376}\n",
      "content='' additional_kwargs={} response_metadata={} id='lc_run--f5fbb422-088f-4dc1-a246-50d3ddfe09ba' chunk_position='last'\n"
     ]
    }
   ],
   "source": [
    "# Streaming support can be also added\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "# use it\n",
    "\n",
    "for part in chatbot.stream({\n",
    "    'question': 'Which model providers offer LLMs?'\n",
    "}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c62cea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Several model providers offer Large Language Models (LLMs). Here are some of the most notable ones:\\n\\n1. **Hugging Face Transformers**: Offers a wide range of pre-trained models, including BERT, RoBERTa, DistilBERT, and more.\\n2. **DeepSpeed**: Provides large language models, such as Megatron-LM and SwitchTransformers, optimized for high-performance computing.\\n3. **Google Cloud AI Platform**: Offers pre-trained LLMs like BERT and RoBERTa, as well as the ability to fine-tune custom models.\\n4. **Amazon SageMaker**: Provides access to pre-trained LLMs like BERT and DistilBERT, as well as tools for building and deploying custom models.\\n5. **Microsoft Azure Machine Learning**: Offers a range of pre-trained LLMs, including BERT and RoBERTa, as well as tools for fine-tuning custom models.\\n6. **IBM Watson Studio**: Provides access to pre-trained LLMs like BERT and DistilBERT, as well as tools for building and deploying custom models.\\n7. **NVIDIA NGC**: Offers a range of pre-trained LLMs, including BERT and RoBERTa, optimized for NVIDIA GPUs.\\n8. **Rasa**: Provides a suite of open-source NLP libraries, including the Rasa SDK, which includes support for LLMs like BERT and RoBERTa.\\n\\nThese are just a few examples, and there may be other model providers offering LLMs as well.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T09:44:25.902851Z', 'done': True, 'done_reason': 'stop', 'total_duration': 28319309000, 'load_duration': 80740800, 'prompt_eval_count': 29, 'prompt_eval_duration': 212769100, 'eval_count': 308, 'eval_duration': 27840652800, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--c835ad42-8fea-4ac0-b0c2-e43f31f1b00e-0', usage_metadata={'input_tokens': 29, 'output_tokens': 308, 'total_tokens': 337})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For asynchronous execution\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "@chain\n",
    "async def chatbot(values):\n",
    "    prompt = await template.ainvoke(values)\n",
    "    return await model.ainvoke(prompt)\n",
    "\n",
    "# use it\n",
    "\n",
    "await chatbot.ainvoke({\n",
    "    'question': 'Which model providers offer LLMs?'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc937e7",
   "metadata": {},
   "source": [
    "### Declarative Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60667bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Several companies and organizations provide Large Language Models (LLMs). Some notable ones include:\\n\\n1. **Meta AI**: Offers a range of pre-trained models, including the popular Transformers-based models like BART, T5, and DistilBERT.\\n2. **Hugging Face**: Provides a suite of LLMs through their Transformers library, including models like RoFormer, Longformer, and XLNet.\\n3. **Google Cloud AI Platform**: Offers various LLMs, such as BERT, RoBERTa, and ALBERT, for use in Google Cloud services.\\n4. **IBM Watson Studio**: Provides access to a range of LLMs, including the IBM Watson Natural Language Understanding model.\\n5. **Microsoft Azure Cognitive Services**: Offers several LLM-based APIs, like Text Analytics and Natural Language Processing (NLP).\\n6. **Amazon SageMaker**: Supports various LLMs, including BERT, RoBERTa, and XLNet, through their pre-built algorithms.\\n\\nKeep in mind that this is not an exhaustive list, as new models are being developed and released regularly. Additionally, some companies may offer proprietary or custom LLMs that are not publicly available.\\n\\nWould you like more information on a specific model or provider?', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-27T13:04:46.0370045Z', 'done': True, 'done_reason': 'stop', 'total_duration': 33050481400, 'load_duration': 8457834500, 'prompt_eval_count': 29, 'prompt_eval_duration': 1167713400, 'eval_count': 250, 'eval_duration': 23259627300, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--89819672-e6d7-46df-a50e-35200094d584-0', usage_metadata={'input_tokens': 29, 'output_tokens': 250, 'total_tokens': 279})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# the building block\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "# combine them with the | operator\n",
    "\n",
    "chatbot = template | model\n",
    "\n",
    "# use it\n",
    "\n",
    "chatbot.invoke({'question': 'Which model providers offer LLMs?'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
