{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629f59a7",
   "metadata": {},
   "source": [
    "# LLM Fundamentals with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2db46b",
   "metadata": {},
   "source": [
    "## Using LLMs in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167db0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...blue! (or maybe grey, or cloudy, or sunny...) What were you going to say?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLMs\n",
    "\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model='llama3.1')\n",
    "\n",
    "model.invoke(\"The sky is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654bf3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-24T14:31:15.3324601Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1180698400, 'load_duration': 109208800, 'prompt_eval_count': 17, 'prompt_eval_duration': 413545100, 'eval_count': 8, 'eval_duration': 650112000, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--85082919-006a-4d56-a4c4-baf469dcd87f-0', usage_metadata={'input_tokens': 17, 'output_tokens': 8, 'total_tokens': 25})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Model\n",
    "\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5430463b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-24T14:31:16.8282216Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1469849700, 'load_duration': 93859400, 'prompt_eval_count': 37, 'prompt_eval_duration': 1172635500, 'eval_count': 3, 'eval_duration': 183269000, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--3eb70514-d595-405b-bc97-e1c83da684fe-0', usage_metadata={'input_tokens': 37, 'output_tokens': 3, 'total_tokens': 40})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Model with SystemMessage interaction\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "system_msg = SystemMessage(\n",
    "    '''You are a helpful assistant that responds to questions with three exclamation marks.'''\n",
    ")\n",
    "human_msg = HumanMessage(\n",
    "    '''What is the capital of France?'''\n",
    ")\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda37149",
   "metadata": {},
   "source": [
    "## Making LLM Prompts Reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495ee68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OpenAI and Cohere offer LLMs through their respective libraries ('openai' and 'cohere').\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# both 'template' and 'model' can be reused many times\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    '''Answer the question based on the context below. \n",
    "    If the question cannot be answered using the information provided, answer \"I don't know.\"\n",
    "\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "\n",
    "    Answer:'''\n",
    ")\n",
    "\n",
    "model = OllamaLLM(model='llama3.1')\n",
    "\n",
    "# 'prompt' and 'completion' are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperforms their\n",
    "        smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers\n",
    "        can tap into tese models through Hugging Face's 'transformers' library, or by utilizing OpenAI and Cohere's offerings through the\n",
    "        'openai' and 'cohere' libraries, respectively.\"\"\",\n",
    "    \"question\":\"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "completion = model.invoke(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "316d54c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hugging Face ('transformers' library), OpenAI ('openai' library), and Cohere ('cohere' library) offer Large Language Models (LLMs).\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2025-10-24T14:41:04.4695804Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15346473400, 'load_duration': 6982090000, 'prompt_eval_count': 148, 'prompt_eval_duration': 5250743800, 'eval_count': 35, 'eval_duration': 3084087000, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--b4019ef5-6dd2-4b55-8640-634b0bee301b-0', usage_metadata={'input_tokens': 148, 'output_tokens': 35, 'total_tokens': 183})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# both 'template' and 'model' can be reused many times\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Answer the question basen on the context below. If the question cannot be answered using hte information provided,\n",
    "        answer with \"I don't know\".'''),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Question: {question}')\n",
    "])\n",
    "\n",
    "model = ChatOllama(model='llama3.1')\n",
    "\n",
    "# 'prompt' and 'completion' are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperforms their\n",
    "        smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers\n",
    "        can tap into tese models through Hugging Face's 'transformers' library, or by utilizing OpenAI and Cohere's offerings through the\n",
    "        'openai' and 'cohere' libraries, respectively.\"\"\",\n",
    "    \"question\":\"Which model providers offer LLMs?\"\n",
    "})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cfcca",
   "metadata": {},
   "source": [
    "## Getting Specific Formats out of LLMs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
